---
title: 'DiffServe: Efficiently Serving Text-to-Image Diffusion Models with Query-Aware Model Scaling'
date: 2125-11-24
permalink: /MLSys2025/Session1/DiffServe/
tags:
  - MLSys2025
  - LLMs
---

including paper: [DiffServe: Efficiently Serving Text-to-Image Diffusion Models with Query-Aware Model Scaling](https://mlsys.org/virtual/2025/poster/3287)

# DiffServe: Efficiently Serving Text-to-Image Diffusion Models with Query-Aware Model Scaling

## 问题与挑战

### 挑战一：为扩散模型构建有效的级联（模型级联失效）

这个挑战的核心是：**如何准确、自动地判断一个查询是否是“简单查询”，从而可以放心地交给小模型处理？**

1. **传统指标完全失效**：
   - 论文通过实验发现，使用现成的、公认的图像质量评估指标（如 **CLIP Score** 和 **PickScore**）作为判别器时，其路由效果**甚至不如随机分类器**。
   - **原因**：这些指标是为特定目的设计的（如评估图文对齐度、在相同提示下比较图像），它们无法可靠地捕捉到人类感知中“轻量级模型生成的图像何时与重量级模型的质量相当”这种细微差别。它们不能作为一个通用的、绝对的质量标准来判断“是否足够好”。
2. **“反直觉”的系统级行为**：
   - 论文观察到一个有趣的现象：当系统将更多查询路由到重量级模型时，整体系统的响应质量指标（FID）**有时反而会变差**。
   - **假设原因**：轻量级模型生成的图像与重量级模型生成的图像在分布上有所不同。全部使用重模型生成的图像集合，其多样性可能反而不如一个由轻、重模型混合生成的图像集合。而后者可能更接近真实世界的图像分布，从而获得更好的FID分数。
   - **这说明了简单路由策略的局限性**，并非所有查询都适合交给大模型。

**结论**：需要一个全新的、专门训练的**判别器**，能够理解“足够好”的质量标准，并能高效地做出精准的路由决策。

### 挑战二：服务级联模型时的资源分配

这个挑战的核心是：**在引入了模型级联后，如何管理系统中相互依赖的资源，以适应动态变化的查询负载？**

1. **复杂的配置空间与相互依赖的变量**：
   - 系统的性能同时受到多个“旋钮”的影响：
     - **置信度阈值 `t`**：直接影响路由决策和质量。
     - **批处理大小 `b₁, b₂`**：影响每个模型的吞吐量和执行延迟。
     - **GPU资源分配 `x₁, x₂`**：决定轻、重模型的并行处理能力。
   - 这些变量**相互耦合**。例如，提高阈值 `t` 会增加重模型的负载，这就需要分配更多GPU (`x₂`) 给它，但这又可能迫使轻模型资源(`x₁`)减少，从而影响整个系统的吞吐量。
2. **动态且波动的查询负载**：
   - 生产环境的查询需求是随时间剧烈变化的。一个固定的配置无法在全天都保持高性能。
   - 系统需要在**低负载时优先考虑质量**（提高阈值，多用重模型），而在**高负载时优先满足延迟SLO**（降低阈值，多用轻模型）。这种动态调整不是简单的规则所能处理的。
3. **延迟目标的保证**：
   - 查询的总延迟包括在轻量级模型和重量级模型处的**执行时间**和**排队时间**。
   - 由于级联的依赖性，一个查询可能经历**两次排队和两次执行**。资源管理器必须能够准确估算这些延迟，并确保其总和不超过SLO，这比服务单一模型要复杂得多。

**结论**：需要一个**协同优化框架**，能够同时考虑所有配置参数和系统约束，并在动态变化的环境中，快速计算出能够最大化质量同时满足SLO的最优资源配置方案。

## 系统框架

![System Framework](../assets/image-DiffServe-1.png)

#### 控制器

- **角色**：系统的控制中心，位于控制路径。
- **功能**：
  - **资源管理**：通过其内部的**资源管理器** 来决定将哪个模型变体分配给哪个工作节点。
  - **动态配置**：设置每个工作节点的**批处理大小** 和轻量级节点所用的**置信度阈值**。
  - **监控与决策**：周期性地从工作节点收集运行时信息（如队列长度、需求），并利用这些信息做出资源分配决策。

#### 模型仓库

- **角色**：存储和管理所有可用的模型。
- **功能**：
  - 负责**注册**和**存储**不同的扩散模型变体（轻量级和重量级）。
  - 存储用于模型级联的**判别器**。

#### 负载均衡器

- **角色**：位于数据路径的入口，负责查询的路由。
- **功能**：
  - 接收客户端查询。
  - **初始路由**：将所有查询首先发送到运行**轻量级扩散模型**的工作节点。
  - **决策与转发**：根据该节点返回的判别结果，要么直接返回图像，要么将查询**转发**给**重量级扩散模型**节点。

#### 工作节点

- **角色**：执行实际模型推理的服务器。
- **功能**：
  - 运行被分配的模型变体（轻量级或重量级）来处理查询。
  - 每个节点维护一个本地队列来缓存待处理的查询。
  - **轻量级模型节点**：额外托管**判别器**，负责生成图像并进行质量评估。
  - 它们的配置（模型类型、批大小、阈值）均由**控制器**动态指定。

## 资源分配

### 核心目标

资源管理器的目标是：**根据实时变化的查询需求，动态调整系统配置，以在满足延迟SLO的前提下，最大化系统的整体响应质量。**

它通过调整三个关键的“旋钮”来实现这一目标：

1. **置信度阈值**
2. **批处理大小**
3. **模型放置**

------

### 核心思想：模型缩放

资源管理器实现了一种称为 **模型缩放** 的机制：

- **低负载时**：提高置信度阈值 `t`，对图像质量要求更严格，将更多查询路由到重量级模型，从而**优先提升系统响应质量**。
- **高负载时**：降低置信度阈值 `t`，允许更多查询由轻量级模型完成，减轻系统负担，从而**优先满足延迟SLO并降低SLO违反率**。

这与传统的**资源 provisioning** 有本质区别：传统方法是为峰值需求准备固定的硬件资源，在非峰值时期会造成资源浪费。而模型缩放则是通过调整模型本身的“服务等级”来适应负载，实现了**在波动负载下更精细、更高效的资源利用**。

------

### 性能建模

为了进行优化，资源管理器需要量化系统行为。它为此建立了三个关键的性能模型：

#### a) 响应质量模型

- 响应质量主要由 **置信度阈值 `t`** 决定。
- **直观关系**：阈值 `t` 越高，系统整体质量越高。
- 在优化问题中，**目标是最大化 `t`**，这直接等价于在给定约束下追求尽可能高的质量。

#### b) 延迟约束

一个查询在系统中的总延迟是其经过轻量级和重量级模型路径上所有时间的总和。

- **执行延迟**：`e(b₁)` 和 `e(b₂)`，表示在特定批处理大小下，轻量级和重量级模型的**单次推理执行时间**。这个时间可以通过离线分析准确获取，是高度确定的。
- **排队延迟**：`q(b₁)` 和 `q(b₂)`，表示查询在轻量级和重量级模型队列中的**等待时间**。为了估算它，系统应用了 **李特尔法则**：
  `等待时间 (W) = 队列长度 (L) / 查询到达率 (λ)`
  - 控制器会周期性地从工作节点收集**实时队列长度 `L`** 和观测到的**到达率 `λ`**，从而动态估算排队延迟。

**总延迟约束** 必须满足服务等级目标 `L`（即最大允许延迟）：
`e(b₁) + q(b₁) + e(b₂) + q(b₂) ≤ L`

这个约束确保了用户体验。

#### c) 吞吐量约束

系统必须有能力处理涌入的查询，不能成为瓶颈。

- **轻量级模型吞吐量约束**：
  所有轻量级模型工作节点的总吞吐量必须 ≥ 总查询需求 `D`。
  `x₁ * T₁(b₁) ≥ D`
  - `x₁`：分配给轻量级模型的GPU数量。
  - `T₁(b₁)`：单个轻量级模型工作节点在批大小为 `b₁` 时的吞吐量。
- **重量级模型吞吐量约束**：
  所有重量级模型工作节点的总吞吐量必须 ≥ 被转发过来的查询量。
  `x₂ * T₂(b₂) ≥ D * f(t)`
  - `x₂`：分配给重量级模型的GPU数量。
  - `T₂(b₂)`：单个重量级模型工作节点在批大小为 `b₂` 时的吞吐量。
  - `f(t)`：**转发率**，即当置信度阈值为 `t` 时，有多大比例的查询会被判别为“困难”而需要重量级模型处理。这个函数通过**离线分析**进行初始化，并在在线服务过程中根据实际路由情况进行更新。
- **资源总量约束**：
  使用的GPU总数不能超过系统可用总数 `S`。
  `x₁ + x₂ ≤ S`

------

### 资源分配问题：混合整数线性规划

基于上述模型，资源分配问题被形式化为一个 **混合整数线性规划** 问题。

- **优化变量**：
  - `x₁`, `x₂`：整数变量，表示分配给轻、重模型的GPU数量。
  - `b₁`, `b₂`：整数变量，表示轻、重模型的批处理大小。
  - `t`：连续变量，表示置信度阈值。
- **目标函数**：
  `max t`
  在满足所有约束的前提下，最大化置信度阈值。这直接对应于**最大化系统的响应质量**。
- **约束条件**：
  就是上面描述的延迟约束和吞吐量约束。

## 知识点

### Frechet Inception Distance (FID) score

FID 是用于评估**生成模型**（如 GANs）性能的一个指标，它通过比较生成图像和真实图像在特征空间中的分布，来计算它们之间的“距离”。**FID 分数越低，表示生成图像的质量和多样性越接近真实图像。**

FID 的核心思想是：**“如果两张图片在视觉上相似，那么它们在某个深层特征空间中的特征向量也应该相似。”**

它不直接比较图像的像素，而是比较图像在一个强大预训练模型（通常是 **Inception-v3**）中提取的**高级特征的统计分布**。

计算 FID 分数的过程可以分为以下几步：

1. **选取特征提取器**：

   - 使用一个在大型数据集（如 ImageNet）上预训练好的 **Inception-v3** 模型。
   - 移除其最后的分类层，使用其前一层的输出（一个 2048 维的向量）作为图像的特征表示。这个特征包含了图像的高级、抽象信息。

2. **提取特征**：

   - 将所有的**真实图片**输入到 Inception-v3 模型中，得到一组 2048 维的特征向量。我们假设这些特征向量服从一个多元高斯分布。
   - 同样，将所有的**生成图片**输入到同一个模型中，得到另一组 2048 维的特征向量。

3. **计算统计量**：

   - 对于真实图片的特征集合，计算其**均值向量（$\mu_r$）** 和**协方差矩阵（$\Sigma_r$）**。
   - 对于生成图片的特征集合，计算其**均值向量（$\mu_g$）** 和**协方差矩阵（$\Sigma_g$）**。

4. **计算 Fréchet 距离**：

   - 使用计算出的统计量，计算两个多元高斯分布之间的 **Fréchet 距离**，也称为 Wasserstein-2 距离。

   - 具体的计算公式如下：$\text{FID} = ||\mu_r - \mu_g||^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})$

   
   其中：
   
   - $||\mu_r - \mu_g||^2$是两个均值向量之间的欧几里得距离的平方。它衡量了两个分布中心点的偏离程度。
   - $\text{Tr}$ 是矩阵的迹（主对角线元素之和）。
   - $\Sigma_r$和$\Sigma_g$分别是真实数据和生成数据的协方差矩阵。
   - 公式的后半部分$\text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})$衡量了两个分布形状（离散程度和相关性）的差异。

### PickScore

PickScore 是一个用于评估**文本到图像生成模型**输出质量的模型，它通过学习**人类对图像的偏好**来判断哪张生成图片能更好地匹配给定的文本描述。

PickScore 的核心思想是模仿人类的选择来判断文本与图像的匹配程度。

- **数据基础：大规模人类偏好数据集**：PickScore 的训练依赖于一个名为 **Pick-a-Pic** 的大规模公开数据集。该数据集包含了大量由真实用户提供的文本提示（prompt）以及他们对于不同生成图像的偏好选择。这为模型学习人类的判断标准奠定了基础。
- **模型架构：基于CLIP微调**：PickScore 建立在强大的 **CLIP模型** 之上。CLIP 本身就能理解图像和文本在同一个语义空间中的关联。PickScore 在此基础上，使用 Pick-a-Pic 数据集对 CLIP 进行**微调**，使其不再是简单地理解图文匹配，而是能够**精准预测人类更偏爱哪张图片**。具体到模型，PickScore 基于 `CLIP-ViT-H-14` 架构并使用了 `laion2B-s32B-b79K` 数据集。
- **工作流程：为图像与文本的匹配程度打分**：给定一段文本描述和一张图像，PickScore 会计算出一个**分数**（score）来评估它们的匹配度。分数越高，代表模型认为该图像越符合文本描述，也越可能受到人类青睐。

### CLIP Score

#### 背景：CLIP 模型

要理解 CLIP Score，必须先了解其基础：**CLIP 模型**。

- **CLIP** 是由 OpenAI 在 2021 年提出的一个开创性模型。
- **核心思想**：通过海量的“图像-文本对”数据进行对比学习，让模型学会将同一个语义空间中的图像和文本进行关联。
- **工作机制**：CLIP 包含两个编码器——一个**图像编码器**和一个**文本编码器**。它将图像和文本分别转换为两个高维向量（特征向量）。如果图像和文本是匹配的，那么它们对应的向量在语义空间中的**余弦相似度**就会很高。

CLIP Score 就是直接利用 CLIP 模型的这个能力来计算出的一个分数。

#### CLIP Score 的计算原理

计算 CLIP Score 的过程非常直接：

1. **输入**：一张图像$I$和一段文本描述$T$。

2. **特征提取**：

   - 将图像$I$输入CLIP的**图像编码器**，得到一个图像特征向量 $v_I$。
   - 将文本$T$输入CLIP的**文本编码器**，得到一个文本特征向量$v_T$。

3. **计算相似度**：

   - 计算这两个特征向量$v_I$和$v_T$之间的**余弦相似度**。余弦相似度的范围在[-1,1]之间，值越高表示方向越一致，即越相似。

4. **标准化与缩放**：

   - 在实际应用中，通常会乘以一个缩放因子（例如 2.5），并对结果进行截断（例如，最小值设为 0），使得分数更易于理解和比较。最终的公式通常表示为：

   $\text{CLIP Score}(I,T)=\omega\cdot max⁡(cos⁡(v_I,v_T),0)$

   其中$\omega$是一个缩放常数（通常为 2.5）。

### cascading diffusion model

#### 基础扩散模型简介

扩散模型是当前最先进的图像生成模型（如DALL-E 2, Midjourney, Stable Diffusion的核心技术）。它的工作原理分为两个过程：

- **前向过程（加噪）**： 逐步向一张原始图片添加高斯噪声，经过很多步（例如1000步）后，图片会变成完全无法辨认的纯噪声。
- **反向过程（去噪）**： 模型学习如何将纯噪声**逆转**这个加噪过程，一步一地去除噪声，最终还原出一张高质量的图片。

**核心思想**： 模型学习的是一个复杂的“去噪”任务。

#### 为什么要“级联”？

基础扩散模型在生成**低分辨率**图片（例如 64x64 或 128x128像素）时表现非常出色。但是，当你想直接生成**高分辨率**图片（例如 1024x1024 或更高）时，会遇到几个大问题：

1. **计算成本极高**： 处理高分辨率图像需要巨大的显存和计算量，训练和推理都非常缓慢。
2. **训练不稳定**： 直接在高维空间（百万像素）中学习去噪非常困难，模型容易失败，难以捕捉精细的细节。
3. **一致性差**： 一步到位生成高分辨率图，可能在整体构图和细节上出现不一致或扭曲。

为了解决这些问题，研究人员提出了 **级联** 的思想。

#### 什么是Cascading Diffusion Model？

**级联扩散模型的核心思想是：将一个困难的高分辨率生成任务，分解为多个由易到难的、顺序连接的子任务。**

可以把它想象成一个 **“接力赛”** 或者 **“瀑布”**：

- **第一棒（基础构图）**：第一个扩散模型生成一张**低分辨率**的、粗糙的图片。这个阶段主要任务是确定图片的**整体布局、颜色、主体轮廓和基本概念**。因为它分辨率低，所以计算快，训练稳定。
- **第二棒（提升细节）**：将第一棒生成的低分辨率图片**上采样**到一个更高的分辨率（例如从64x64到256x256），然后交给第二个扩散模型进行处理。第二个模型的任务是**在已有的粗糙构图基础上，添加合理的细节**，比如让纹理更清晰，物体形状更明确。
- **第三棒及更多（精修）**：这个过程可以重复多次。第三个模型接收第二棒的输出，并将其上采样到最终的目标分辨率（例如1024x1024）。它的任务是**添加极其精细的细节**，比如皮肤的毛孔、头发的丝缕、树叶的脉络等。

**关键点：**

- 每一个后续模型都**依赖于前一个模型的输出**。它是在“完善”和“细化”前一个结果，而不是从头开始创造。
- 每个阶段的模型都只专注于解决自己分辨率级别的问题，这使得每个模型都更容易训练和优化。
- 在级联的过程中，通常会引入 **“数据增强”** 技术，比如对低分辨率输入进行轻微的抖动、噪声等，以提升超分辨率模型的鲁棒性，防止它产生伪影或过度平滑。

本文中的cascading diffusion model不一样

本文的**Diffusion Model Cascades（扩散模型级联）**是一种**系统调度策略**。它包含：

- 一个 **Discriminator（判别器/路由器）**：像一个智能过滤器，快速判断一个文本提示是“容易生成”的还是“困难”的。
- 一个 **Lightweight Model（轻量级模型, L）**：速度快，但能力稍弱。擅长处理简单提示。
- 一个 **Heavyweight Model（重量级模型, H）**：速度慢，但能力强大。专门处理复杂提示。
