---
title: 'MLSys 2025'
date: 2025-11-21
permalink: #/posts/
tags:
  - MLSys
---



更新来自MLsys2025的论文解读

## [Session 1: LLM and Diffusion Model Serving](https://mlsys.org/virtual/2025/papers.html?filter=session&search=Session 1: LLM and Diffusion Model Serving)

 [FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving](..\post\MLSys2025\FlashInfer\) 

[DiffServe: Efficiently Serving Text-to-Image Diffusion Models with Query-Aware Model Scaling](..\post\MLSys2025\DiffServe\)

[FastTree: Optimizing Attention Kernel and Runtime for Tree-Structured LLM Inference](..\post\MLSys2025\FastTree\)

[Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving](..\post\MLSys2025\Rethinking\)
